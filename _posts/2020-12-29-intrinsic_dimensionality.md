---
title: 'Intrinsic dimensionality'
date: 2020-12-29
permalink: /posts/inverse_matrices/
tags:
  - tutorial
  - mathematics
  - linear algebra
  - matrices
---

THIS POST IS CURRENTLY UNDER CONSTRUCTION

An important concept in linear algebra and the data sciences is the idea of **intrinsic dimensionality**.  I found that in my formal education this concept was never explicitly taught; however, it undergirds so many concepts in linear algebra and data analysis. In this post I will discuss the difference between the **dimensionality** of an object versus its **intrinsic dimensionality**.  This concept provides a nice framework for understanding such broad concepts as the [rank of a matrix](https://en.wikipedia.org/wiki/Rank_(linear_algebra)) in linear algebra as well as [dimension reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction) and [feature selection](https://en.wikipedia.org/wiki/Feature_extraction) in machine learning. 

**Dimensionality**

Let's start with a basic question: what does it mean for an object to be three-dimensional versus two-dimensional?  More generally, what does it mean for an object to be $D$-dimensional? 
