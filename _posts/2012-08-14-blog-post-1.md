---
title: 'Demystifying measure-theoretic probability theory (part 1: probability spaces)'
date: 2015-08-14
permalink: /posts/post1/
tags:
  - cool posts
  - category1
  - category2
---

*In this series of posts, I will present my understanding of some basic concepts in measure theory — the mathematical study of objects with “size”— that have enabled me to gain a deeper understanding into the foundations of probability theory.*

Introduction
-----

As a computer science undergraduate student, I was taught the basic and incomplete version of probability theory in which discrete outcomes (e.g. a dice roll) are treated quite differently from continuous outcomes (e.g. the temperature outside).  For example, the expectation of a discrete random variable $X$ is given by. 

$$E(X) := \sum_x P(X=x)$$  

whereas if $X$ is continuous its expectation is given by    

$$E(X) := \int_x x \ f(x) \ dx$$

where $f(x)$ is $X$'s density function. 

Not only did I find this division to be unsatisfying, but as I continued to study statistics and machine learning through grad school, I found it to be inadequate for a deeper understanding into the workings of the topics that I was studying. 

I learned that this division, between continuous and discrete distributions, is actually a bridge over a deeper and more complete theory of probability, based on measure theory, that not only unifies the discrete and continuous scenarios, but also extends them. 

In fact, I was surprised to learn that the very formal definition of probability requires measure theory! It is as if the very first step into probability plunges one into a crevice of mathematics. It is no wonder why teachers build a bridge to cross this crevice and avoid measure theory altogether. Sadly, this bridge comes at the cost of a less satisfying, and more tedious explanation of probability.

A measure theoretic foundation for probability
------

I'll introduce a bunch of terms in my definition for probability and in the following sections, we will define and discuss each of them. First, the formal definition of a **probability space**:

<span style="color:#0060C6">**Definition 1:** A **probability space** is a measure space ($\Omega$, $E$, $P$) where $P(\Omega) = 1$ where </span>
1. <span style="color:#0060C6  ">The set $\Omega$, is called the **sample space**.</span>
2. <span style="color:#0060C6">The sigma-algebra over $\Omega$, denoted $E$, called the set of **events**.</span>
3. <span style="color:#0060C6">The measure $P$ for the measureable space $(\Omega, E)$ is the **probability measure**.</span>

Sigma-algebra? Measure space? Let's introduce each of these ideas, and then we will come back to this full three-part definition.

Sigma-algebras
------

Measure theory is all about abstracting the idea of "size". What do we mean by size?  Size is a number that we attribute to an object that obeys a specific, intuitive property: if we break the object apart, the sizes of the pieces should add up to the size of the whole. 

There are many phenomena that follow this basic "size"-like idea including such phenomena as mass, length, and volume (and as we will see later, probability). For example, if we have a ball of clay and we split the ball of clay into two, then the masses of the two smaller balls of clay will add up to the mass of the original ball of clay.  

Before we can discuss the "sizes" of objects and pieces of objects, we need a mathematical way to describe an object. Measure theory uses a set $F$ to denote the object that we are considering. For example, $F$ may represent a ball of clay. 

Given our object/set $F$, we then need a way to describe how $F$ can be broken into pieces. This notion of "breaking an object into pieces" is described by a sigma-algebra over $F$:

**Definition 2:** Given a set $F$ and a collection of subsets $\mathcal{F}$, the collection $\mathcal{F}$ is called a $\boldsymbol{\sigma}**-algebra** if it satisfies the following conditions:
1. $\emptyset \in \mathcal{F}$
2. $A \in \mathcal{F} \implies A^c \in \mathcal{F}$
3. $A_1, A_2, \dots \in \mathcal{F} \implies \bigcup_{i=1}^\infty \in \mathcal{F}$

Intuitively, each element of the sigma-algebra (i.e. a subset of F), represents a "piece" of the object. The first criteria in the definition above establishes a "null piece" (i.e. a piece of zero size) can be considered a piece of the object.  The second criteria establishes the fact that if we break off a piece, $A$, of the object, then the remaining object $A^c$ (the compliment of $A$) is also a valid piece. Finally, the third criteria establishes the fact that if we glue a countable set of pieces together, the resultant piece is also a piece of the object.

Another way to imagine this is to think of $F$ as a ceramic plate that is cracked. The sigma-algebra describes all the ways that the plate can fall apart along the cracks. The figure below illustrates this:

![sigma_algebra](https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/sigma_algebra.png)


Measure spaces
------

Okay, we've spent a while thinking about representing objects and pieces of an object. Now how do we assign each piece a "size"? This is where a measure comes into play. A measure is simply a function that assigns each piece of an object a size.  As we discussed before, the sizes of two pieces of an object must add up to the size of the whole, which is exactly how a measure is defined:

**Definition 3:** Given a set $F$ and a $sigma-algebra$ on $F$, denoted $\mathcal{F}$, the function

$$\mu : \mathcal{F} \rightarrow \mathbb{R}$$

is a **measure** if the following properties hold for $\mu$:
1. Nonnegative: 

$$\forall A \in \mathcal{F}, \mu(A) \geq 0$$
2. Empty set has zero measure: 

$$\mu(\emptyset)= 0$$
3. Countable additivity: Given $A, B \in \mathcal{F}$ where $A \cap B = \emptyset$, 

$$\mu(A \cup B) = \mu(A) + \mu(B)$$
