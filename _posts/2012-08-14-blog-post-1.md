___
title: 'Demystifying measure-theoretic probability theory (part 1: probability spaces)'
date: 2012-08-14
permalink: /posts/measure_theory_1/
tags:
  - mathematics
  - probability
  - statistics
  - tutorial
___

*In this series of posts, I will present my understanding of some basic concepts in measure theory — the mathematical study of objects with “size”— that have enabled me to gain a deeper understanding into the foundations of probability theory.*

Introduction
-----

As a computer science undergraduate student, I was taught the basic and incomplete version of probability theory in which discrete outcomes (e.g. a dice roll) are treated quite differently from continuous outcomes (e.g. the temperature outside).  For example, the expectation of a discrete random variable $X$ is given by. 

$$E(X) := \sum_x P(X=x)$$  

whereas if $X$ is continuous its expectation is given by    

$$E(X) := \int_x x \ f(x) \ dx$$

where $f(x)$ is $X$'s density function. 

Not only did I find this division to be unsatisfying, but as I continued to study statistics and machine learning through grad school, I found it to be inadequate for a deeper understanding into the workings of the topics that I was studying. 

I learned that this division, between continuous and discrete distributions, is actually a bridge over a deeper and more complete theory of probability, based on measure theory, that not only unifies the discrete and continuous scenarios, but also extends them. 

In fact, I was surprised to learn that the very formal definition of probability requires measure theory! It is as if the very first step into probability plunges one into a crevice of mathematics. It is no wonder why teachers build a bridge to cross this crevice and avoid measure theory altogether. Sadly, this bridge comes at the cost of a less satisfying, and more tedious explanation of probability.

A measure theoretic foundation for probability
------

I'll introduce a bunch of terms in my definition for probability and in the following sections, we will define and discuss each of them. First, the formal definition of a **probability space**:

A **probability space** is a measure space ($\Omega$, $E$, $P$) where $P(\Omega) = 1$ where 
1. The set $\Omega$, is called the **sample space**.
2. The sigma-algebra over $\Omega$, denoted $E$, called the set of **events**.
3. The measure $P$ for the measureable space $(\Omega, E)$ is the **probability measure**.

Sigma-algebra? Measure space? Let's introduce each of these ideas, and then we will come back to this full three-part definition.

Sigma-algebras
------

Measure theory is all about abstracting the idea of "size". What do we mean by size?  Size is a number that we attribute to an object that obeys a specific, intuitive property: if we break the object apart, the sizes of the pieces should add up to the size of the whole. 

There are many phenomena that follow this basic "size"-like idea including such phenomena as mass, length, and volume (and as we will see later, probability). For example, if we have a ball of clay and we split the ball of clay into two, then the masses of the two smaller balls of clay will add up to the mass of the original ball of clay.  

Before we can discuss the "sizes" of objects and pieces of objects, we need a mathematical way to describe an object. Measure theory uses a set $F$ to denote the object that we are considering. For example, $F$ may represent a ball of clay. 

Given our object/set $F$, we then need a way to describe how $F$ can be broken into pieces. This notion of "breaking an object into pieces" is described by a sigma-algebra over $F$:

![My dog](/images/Baxter.jpg)
