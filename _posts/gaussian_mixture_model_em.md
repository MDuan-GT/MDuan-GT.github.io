

A Gaussian mixture model (GMM) is a probabilistic model that is often used for data clustering. Given observed data points X := x1, . . . , xn, we assume the following proba- bilistic generative process. There exist k multi-variate Gaussian distributions φ1 , . . . , φk . When we generate a data point xi, we first randomly select one of these k distributions according to a categorical distribution parameterized by probabilities λ1 , . . . , λk . That is, λj is the probability of selecting the jth Gaussian. Once selected, we randomly sample xi from the this selected Gaussian. An example of a Gaussian mixture model is depicted in Figure 1.
This model assumes that each cluster in the data is defined by a Gaussian distri- bution. Then, given the observed data points x1, . . . , xn, our clustering task reduces to inferring both the means and variances of the latent Gaussians and then assigning each data point to a Gaussian. That is, each cluster in the data is defined by a Gaussian char- acterized by means μ1, . . . , μk and covariance matrices Σ1, . . . , Σk. We’ll let Θ represent the set of all of the parameters. That is,
